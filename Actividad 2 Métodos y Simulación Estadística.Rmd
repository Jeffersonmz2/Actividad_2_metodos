---
title: "Actividad 2 Métodos y Simulación Estadística"
author: "Jefferson Martinez"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
source("scrip_actividad_2.R")
library(tibble)
set.seed(123)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Problema 1: Estimación de la probabilidad y la media
Una empresa de servicio técnico recibe, en promedio, 5 solicitudes de reparación por hora. Suponiendo que el número de solicitudes sigue una distribución de Poisson, realiza las siguientes actividades:

## a. Cálculo de probabilidad teórica:
- ### Calcula la probabilidad de que en una hora lleguen exactamente 3 solicitudes usando la fórmula de la distribución de Poisson. Expresa el resultado como P(X=3)
.
La probabilidad de que **P(X=3)** es  **`r xes3`** 

## b Simulación con una muestra:
- ### Genera una muestra aleatoria de tamaño n=1,000

*`r muestra`*

- ### Calcula la frecuencia relativa para X=3
 
 La frecuencia relativa para **X=3** es **`r frecuencia_relativa`**
 
 - ### Compara e interpreta el resultado frente a la probabilidad teórica.

 la diferencia entre la probabilidad la simulada y la teoríca   es **`r xes3-frecuencia_relativa`**
 
 
Este resultado ilustra un concepto fundamental en estadística conocido como la Ley de los Grandes Números. Esta ley establece que a medida que el número de repeticiones de un experimento aleatorio (en este caso, `r n` simulaciones) aumenta, la frecuencia relativa de un evento se acerca cada vez más a su probabilidad teórica.

En este ejercicio, la simulación de `r n` eventos nos dio un valor `r frecuencia_relativa` que está muy cerca del valor real `r xes3`. Si hubiéramos realizado 10,000 o 100,000 simulaciones, es muy probable que la frecuencia relativa se hubiera acercado aún más a la probabilidad teórica.

**En resumen:**

La probabilidad teórica es el valor exacto, calculado a partir de las propiedades de la distribución de probabilidad (en este caso, la distribución de Poisson

La probabilidad empírica es una estimación del valor real, obtenida a través de la experimentación o simulación.

- ### Genera 100 muestras aleatorias de tamaño n=1,000.
`r muestra`

- ### Calcula la frecuencia relativa para X=3 en cada muestra.
`r frecuencias_relativas`

- ### Construye un gráfico de dispersión:
```{r grafico_1, echo=FALSE, fig.width=12, fig.height=10, warning = FALSE}
plot(datos_grafico$Simulacion, datos_grafico$Frecuencia,
     main = "Frecuencias relativas de X=3 en 100 simulaciones",
     xlab = "Número de Simulación",
     ylab = "Frecuencia Relativa (X=3)",
     pch = 19,
     col = "blue")


abline(h = xes3, col = "red", lty = 2, lwd = 2)

# Añadir la leyenda en una posición que no estorbe
legend("bottomright",
       legend = c("Frecuencia Relativa", "Probabilidad Teórica"),
       col = c("blue", "red"), pch = c(19, NA), lty = c(NA, 2), lwd = c(NA, 2),
       bg = "white",
       box.lwd = 0.5)
```

## d Impacto del tamaño muestral:

- ### Genera muestras aleatorias con tamaños: 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900 y 1,000. Agrega valores si consideras que mejora el análisis de los resultados.


- ### Calcula la frecuencia relativa de X=3 para cada tamaño.
```{r calcular_frecuencias_relativas, echo=FALSE, warning = FALSE}
#Genera muestras aleatorias con tamaños:
# Definir los tamaños muestrales
sample_sizes <- c(5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400,500, 600, 700, 800, 900, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000)

# Vector para almacenar las frecuencias relativas
rel_freqs <- numeric(length(sample_sizes))
# Generar muestras y calcular frecuencias relativas
for (i in 1:length(sample_sizes)) {
  n <- sample_sizes[i]
  samples <- rpois(n, lambda = 5)
  rel_freq <- sum(samples == 3) / n
  rel_freqs[i] <- rel_freq
  cat("Tamaño muestral", n, ": Frecuencia relativa =", rel_freq, "\n")
}

```
- ### Construye un gráfico de dispersión:

- Eje X: Indexación (1 al 20) por cada tamaño muestral.

- Eje Y: Frecuencias relativas fn(X=3).

- Dibuja la línea en P(X=3)  y describe si aparece una tendencia.

```{r grafico_2, echo=FALSE, fig.width=12, fig.height=10, warning = FALSE}
# Construir el gráfico de dispersión

plot(1:length(sample_sizes), rel_freqs, 
     xlab = "Indexación (1 al 20) por tamaño muestral",
     ylab = "Frecuencias relativas fn(X=3)",
     main = "Impacto del tamaño muestral en la frecuencia relativa de X=3",
     pch = 19, col = "blue")

# Dibujar la línea horizontal en P(X=3)
abline(h = xes3, col = "red", lty = 2)
legend("topright", legend = c("Frecuencias relativas", "P(X=3)"),
       col = c("blue", "red"), pch = c(19, NA), lty = c(NA, 2))
```
## c.Convergencia de la media muestral:
- Genera 100 muestras de tamaño n=1,000.
```{r generar_100_muestras, echo=FALSE, warning = FALSE}

# Definir parámetros
lambda <- 5  # Media teórica de la distribución de Poisson
n <- 1000    # Tamaño de cada muestra
num_samples <- 100  # Número de muestras

# Generar 100 muestras de tamaño n=1000 y calcular promedios muestrales
sample_means <- numeric(num_samples)
for (i in 1:num_samples) {
  sample <- rpois(n, lambda = lambda)
  sample_means[i] <- mean(sample)
}
```
- Calcula el promedio muestral de solicitudes en cada muestra.
```{r calcular_promedio_muestral, echo=FALSE, warning = FALSE}

# Mostrar la media teórica
cat("Media teórica λ =", lambda, "\n\n")

# Imprimir los promedios muestrales
for (i in 1:num_samples) {
  cat("Muestra", i, ": Promedio muestral =", sample_means[i], "\n")
}
```
### Construye un gráfico de dispersión:

- Eje X: Indexación por cada muestra (1 a 100).

- Eje Y: Promedios muestrales.

- Traza la línea horizontal en la media teórica (λ
) y analiza la tendencia.

```{r grafico_3, echo=FALSE, fig.width=12, fig.height=10, warning = FALSE}
# Construir el gráfico de dispersión
plot(1:num_samples, sample_means,
     xlab = "Indexación (Muestra 1 a 100)",
     ylab = "Promedios muestrales",
     main = "Convergencia de la media muestral (n=1000, λ=5)",
     pch = 19, col = "blue")

# Trazar la línea horizontal en la media teórica
abline(h = lambda, col = "red", lty = 2)
legend("topright", legend = c("Promedios muestrales", "Media teórica λ=5"),
       col = c("blue", "red"), pch = c(19, NA), lty = c(NA, 2))

```

## f Impacto del tamaño muestral en la media:

- Genera muestras aleatorias con tamaños: 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900 y 1,000. Agrega valores si consideras que mejora el análisis de los resultados.
```{r generar_muestras_lambda_5, echo=FALSE, warning = FALSE}
sample_sizes_lambda5_5 <- c(5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300,400, 500, 600, 700, 800, 900, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000)

# Vector para almacenar los promedios muestrales
sample_means <- numeric(length(sample_sizes_lambda5_5))
```
- Calcula el promedio muestral para cada tamaño.
```{r calcular_promedio_muestral_lambda_5, echo=FALSE, warning = FALSE}

# Generar muestras y calcular promedios muestrales
for (i in 1:length(sample_sizes_lambda5_5)) {
  n <- sample_sizes_lambda5_5[i]
  sample <- rpois(n, lambda = lambda)
  sample_means[i] <- mean(sample)
  cat("Tamaño muestral", n, ": Promedio muestral =", sample_means[i], "\n")
}

# Mostrar la media teórica
cat("\nMedia teórica λ =", lambda, "\n\n")
```
### Construye un gráfico de dispersión:

- Eje X: Indexación (1 al 20) por cada tamaño muestral.

- Eje Y: Promedios muestrales.

- Dibuja la línea horizontal en la media teórica (λ) y compara si el promedio se aproxima a medida que crece el tamaño.
```{r grafico_4, echo=FALSE, fig.width=12, fig.height=10, warning = FALSE}
# Construir el gráfico de dispersión
plot(1:length(sample_sizes), sample_means,
     xlab = "Indexación (1 al 20) por tamaño muestral",
     ylab = "Promedios muestrales",
     main = "Impacto del tamaño muestral en la media muestral (λ=5)",
     pch = 19, col = "blue")

# Trazar la línea horizontal en la media teórica
abline(h = lambda, col = "red", lty = 2)
legend("topright", legend = c("Promedios muestrales", "Media teórica λ=5"),
       col = c("blue", "red"), pch = c(19, NA), lty = c(NA, 2))
```

## Problema 2: Propiedades de los estimadores
Un centro de atención médica registra el tiempo de espera (en minutos) de los pacientes antes de ser atendidos. Se sabe que estos tiempos siguen una distribución Gamma con parámetros conocidos α=3
 (forma) y σ=2
 (escala). El parámetro que se supone desconocido en este problema es la media poblacional μ = ασ.
 

Sea X1,X2,…,Xn una muestra aleatoria de tamaño n independiente e identicamente distribuida extraída de esta población. Se proponen los siguientes estimadores para μ
:

Estimador 1:

$$
\hat{\mu}_{1} = \frac{1}{n} \sum_{i=1}^{n} X_{i}
$$

Estimador 2:
$$
\hat{\mu}_{2} = \frac{\min(X_{1}, \dots, X_{n}) + \max(X_{1}, \dots, X_{n})}{2}
$$

Estimador 3:
$$
\hat{\mu}_{3} = X_{(1)}
$$

Estimador 4:
$$
\hat{\mu}_{4} = \frac{1}{n+1} \sum_{i=1}^{n} X_{i}
$$

Realiza las siguientes actividades:

### a. Simulación de estimadores:
- Genera 100 muestras de tamaño n=10
de una distribución Gamma con parámetros α=3
 y σ=2

```{r gama_generar_muestras, echo=FALSE, warning = FALSE}
# Parámetros de la distribución Gamma
alpha <- 3
sigma <- 2
n <- 10  # Tamaño muestral
num_samples <- 100  # Número de muestras

```
- Para cada muestra, calcula los estimadores correspondientes. Luego, grafica los resultados utilizando una curva de densidad o un histograma de densidades para cada estimador.

```{r gama_calcular_estimadores, echo=FALSE, warning = FALSE}
# Vectores para almacenar los estimadores
est1 <- numeric(num_samples)  # μ̂1: Media muestral
est2 <- numeric(num_samples)  # μ̂2: (min + max)/2
est3 <- numeric(num_samples)  # μ̂3: Mínimo (X(1))
est4 <- numeric(num_samples)  # μ̂4: Suma / (n+1)

# Generar las 100 muestras y calcular estimadores
for (i in 1:num_samples) {
  sample <- rgamma(n, shape = alpha, scale = sigma)
  est1[i] <- mean(sample)
  est2[i] <- (min(sample) + max(sample)) / 2
  est3[i] <- min(sample)
  est4[i] <- sum(sample) / (n + 1)
}
resultados <- tibble(
  `Estimador 1` = est1,
  `Estimador 2` = est2,
  `Estimador 3` = est3,
  `Estimador 4` = est4
)

resultados
```
```{r grafico_5, echo=FALSE, fig.width=12, fig.height=10, warning = FALSE}
# Configurar panel para 4 gráficos (2x2) con márgenes ajustados
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))  # Márgenes: bottom, left, top, right

# Graficar curva de densidad para cada estimador
plot(density(est1), main = "Densidad de μ̂1 (Media muestral)", xlab = "Valor del estimador", col = "blue", lwd = 2)
abline(v = alpha * sigma, col = "red", lty = 2)

plot(density(est2), main = "Densidad de μ̂2 ((min + max)/2)", xlab = "Valor del estimador", col = "green", lwd = 2)
abline(v = alpha * sigma, col = "red", lty = 2)

plot(density(est3), main = "Densidad de μ̂3 (Mínimo)", xlab = "Valor del estimador", col = "purple", lwd = 2)
abline(v = alpha * sigma, col = "red", lty = 2)

plot(density(est4), main = "Densidad de μ̂4 (Suma/(n+1))", xlab = "Valor del estimador", col = "orange", lwd = 2)
abline(v = alpha * sigma, col = "red", lty = 2)

# Resetear configuración de gráficos
par(mfrow = c(1, 1), mar = c(5, 4, 4, 2) + 0.1)  # Restaurar márgenes predeterminados
```
- ### Realiza una interpretación de los gráficos obtenidos.
**Densidad de μ̂₁EStimador 1 (Media muestral**

Este estimador, la media muestral, es insesgado para μ = 6, ya que la esperanza de la media muestral de una Gamma es igual a la media poblacional. La cercanía de la curva al valor teórico indica que es un estimador eficiente y confiable para estimar el tiempo de espera promedio. En el contexto del centro médico, esto sugiere que promediar los tiempos de espera de 10 pacientes proporciona una buena estimación del tiempo medio esperado.

**Densidad de μ̂₂ Estimador 2((min + max)/2)**

La curva de densidad también se centra cerca de 6, pero muestra una distribución más amplia y ligeramente asimétrica, con colas más pronunciadas que μ̂₁.
Este estimador, el promedio del mínimo y el máximo de la muestra, es aproximadamente insesgado. a varianza es mayor que la de μ̂₁, reflejando menor eficiencia con un tamaño con n=10, donde los extremos (mínimo y máximo) son más influyentes. 

**Densidad de μ̂₃ Estimador 3 (Mínimo)**


La curva de densidad está desplazada hacia la izquierda, con un pico alrededor de 0.5-1 y una cola que se extiende hacia valores mayores, pero muy por debajo de 6. el mínimo de la muestra, es fuertemente sesgado hacia abajo, lo que coincide con el pico observado. Esto indica que el mínimo subestima significativamente el tiempo de espera promedio (μ = 6), siendo un mal estimador para este propósito. En un centro médico, usar el tiempo de espera mínimo como estimador de la media no reflejaría la experiencia típica de los pacientes.


**Densidad de μ̂₄ Estimado 4 (Suma/(n+1))**


La curva de densidad está ligeramente desplazada hacia la izquierda de 6, con un pico alrededor de 5-5.5 y una forma similar a la de μ̂₁ pero más sesgada .Este estimador, una versión ajustada de la media muestral (suma dividida por n+1 en lugar de n), introduce un sesgo sistemático hacia abajo. Aunque sigue siendo más cercano a μ = 6 que μ̂₃, su eficiencia es menor que la de μ̂₁ debido al sesgo.

### Conclusiones
- Mejor estimador: μ̂₁ Estimador 1 (media muestral) es el más adecuado, ya que está centrado en la media teórica μ = 6 y tiene menor varianza, reflejando una estimación precisa del tiempo de espera promedio.
- Sesgo y eficiencia: μ̂₃ Estimador 3 (mínimo) tiene el mayor sesgo y es inapropiado para estimar μ. μ̂₄ tiene un sesgo moderado, mientras que μ̂₂, aunque aproximado, es menos eficiente que μ̂₁.
- Contexto práctico: Para el centro de atención médica, usar μ̂₁ sería lo más recomendable, ya que captura mejor el tiempo de espera promedio de los pacientes, mientras que los otros estimadores (especialmente μ̂₃) no representan adecuadamente la media poblacional con n=10.

## Problema 3:Teorema del limite central

En una planta de fabricación de componentes electrónicos, se modela el tiempo (meses) de funcionamiento continuo de una máquina antes de necesitar mantenimiento mediante una distribución Exponencial. El análisis ha determinado que el tiempo hasta el primer mantenimiento sigue una distribución Exponencial con parámetro λ=0.16

La distribución exponencial definida por:
$$
X \sim \text{Exp}(\lambda)
$$

### a. Cálculo de la media y varianza de la población:

Para la distribución exponencial su media:
$$
\mathbb{E}[X] = \frac{1}{\lambda}
$$
la varianza: 
$$
\text{Var}(X) = \frac{1}{\lambda^{2}}
$$



```{r}
library(tibble)
library(tidyverse)

lambda <- 0.16
mu <- 1/lambda
varX <- 1/(lambda^2)
tibble(media_poblacional = mu, var_poblacional = varX)
```
Una maquina puede funcionar alrededor de 6.25 meses antes del mantenimiento.El valor de la varianza es bastante alto por lo tanto habra maquinas que fallen mucho antes o tal vez mucho despues del valor que estamos estimando

### b. Gráfico de la curva de densidad:

Grafica la función de densidad de la distribución Exponencial que describe la población.

Explica cómo el parámetro λ
 afectan la forma de la curva.

Interpreta el modelo en relación con el mantenimiento predictivo y la probabilidad de fallos prematuros o tardíos.

### c. Comparación de parámetros, estimadores y estimaciones: Toma 10 muestras aleatorias de tamaño n=200
 de la población Exponencial de parámetro λ
 usando la función rexp(n, rate=lambda) de R y establece una semilla como por ejemplo set.seed(123) para asegurar la reproducibilidad de los resultados. Para cada muestra:

Elabora un histograma e interpreta la distribución de los datos.

Calcula la media y varianza muestral y compara con los valores poblacionales.

Analiza los siguientes conceptos:

Parámetros: Identifica los valores poblacionales reales.

Estimadores: Define las fórmulas utilizadas para estimar los parámetros.

Estimaciones: Interpreta los valores obtenidos y su relación con las muestras.

### d. Aplicación del Teorema del Límite Central para n=200
:

Genera 100 muestras de tamaño n=200
 de la población Exponencial.

Calcula la media muestral de cada muestra y elabora un histograma de las 100 medias muestrales.

Obtén el promedio y la varianza de estas 100 medias muestrales.

Aplica un test de normalidad (α=0.05
) a las 100 medias muestrales e interpreta los resultados.

Explica cómo se evidencia el Teorema del Límite Central en el comportamiento de las medias muestrales, considerando:

Distribución de las medias muestrales.

Comparación de la media y varianza muestral con las esperadas.

### e. Aplicación del Teorema del Límite Central variando n:

Repite el análisis anterior extrayendo 100 muestras de cada uno de los siguientes tamaños: n=
 5, 10, 80, 200, 500 y 2,000.

Para cada tamaño de muestra n
:

Calcula el promedio y la varianza de las 100 medias muestrales.

Elabora un histograma de las 100 medias muestrales.

Aplica un test de normalidad (α=0.05
) y discute los resultados.

Concluye sobre la relación entre el tamaño muestral y la validez del Teorema del Límite Central, analizando:

Comportamiento de la distribución de las medias muestrales.

Convergencia de la media y varianza muestral hacia los valores teóricos.




